{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16add4f6-c923-4181-889d-8b8487a5d779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face detector model...\n",
      "[INFO] loading face mask detector model...\n",
      "[INFO] starting video stream...\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import load_model\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "from tracker import EuclideanDistTracker\n",
    "from itertools import combinations\n",
    "from non_max_suppresion import non_max_suppression_fast\n",
    "from ipynb.fs.full.detect_people import yolo\n",
    "from ipynb.fs.full.detect_mask import detect_and_predict_mask\n",
    "from scipy.spatial import distance as dist\n",
    "import social_distancing_config as config \n",
    "\n",
    "\n",
    "tracker = EuclideanDistTracker()\n",
    "centroid_dict = dict()\n",
    "\n",
    "net = cv2.dnn.readNet('yolo_tiny/yolov3-tiny.weights', 'yolo_tiny/yolov3-tiny.cfg')\n",
    "#classes = ['person']\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = f.read().splitlines()\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "# load our serialized face detector model from disk\n",
    "print(\"[INFO] loading face detector model...\")\n",
    "prototxtPath = r\"face_detector/deploy.prototxt\"\n",
    "weightsPath = r\"face_detector/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n",
    "# load the face mask detector model from disk\n",
    "print(\"[INFO] loading face mask detector model...\")\n",
    "maskNet = load_model('mask_detector.model')\n",
    "\n",
    "# initialize the video stream and allow the camera sensor to warm up\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream('http://192.168.29.49:8080/video').start()\n",
    "time.sleep(2.0)\n",
    "# loop over the frames from the video stream\n",
    "while True:\n",
    "    # grab the frame from the threaded video stream and resize it\n",
    "    # to have a maximum width of 400 pixels\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=400)\n",
    "    \n",
    "    ##Call YOLO (detect_people function)##\n",
    "    \n",
    "    results = yolo(frame, net, classes, font)\n",
    "    \n",
    "    # initialize the set of indexes that violate the minimum social distance\n",
    "    violate = set()\n",
    "\n",
    "    # ensure there are *at least* two people detections (required in\n",
    "    # order to compute our pairwise distance maps)\n",
    "    if len(results) >= 2:\n",
    "        # extract all centroids from the results and compute the\n",
    "        # Euclidean distances between all pairs of the centroids\n",
    "        centroids = np.array([r[2] for r in results])\n",
    "        D = dist.cdist(centroids, centroids, metric=\"euclidean\")\n",
    "\n",
    "        # loop over the upper triangular of the distance matrix\n",
    "        for i in range(0, D.shape[0]):\n",
    "            for j in range(i + 1, D.shape[1]):\n",
    "                # check to see if the distance between any two\n",
    "                # centroid pairs is less than the configured number\n",
    "                # of pixels\n",
    "                if D[i, j] < config.MIN_DISTANCE:\n",
    "                    # update our violation set with the indexes of\n",
    "                    # the centroid pairs\n",
    "                    violate.add(i)\n",
    "                    violate.add(j)\n",
    "\n",
    "    # loop over the results\n",
    "    for (i, (prob, bbox, centroid)) in enumerate(results):\n",
    "        # extract the bounding box and centroid coordinates, then\n",
    "        # initialize the color of the annotation\n",
    "        (startX, startY, endX, endY) = bbox\n",
    "        (cX, cY) = centroid\n",
    "        color = (0, 255, 0)\n",
    "\n",
    "        # if the index pair exists within the violation set, then\n",
    "        # update the color\n",
    "        if i in violate:\n",
    "            color = (0, 0, 255)\n",
    "            text = str('Maintain Social Distancing!')\n",
    "            cv2.putText(frame, text, (50, 30),\n",
    "            font, 0.9, color, 2)\n",
    "\n",
    "        # draw (1) a bounding box around the person and (2) the\n",
    "        # centroid coordinates of the person,\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "        #cv2.circle(frame, (cX, cY), 5, color, 1)\n",
    "\n",
    "    \n",
    "    # detect faces in the frame and determine if they are wearing a\n",
    "    # face mask or not\n",
    "    \n",
    "    (locs, preds) = detect_and_predict_mask(frame, faceNet, maskNet)  ##from detect_mask fuction\n",
    "\n",
    "    # loop over the detected face locations and their corresponding\n",
    "    # locations\n",
    "    for (box, pred) in zip(locs, preds):\n",
    "        # unpack the bounding box and predictions\n",
    "        (startX, startY, endX, endY) = box\n",
    "        (mask, withoutMask) = pred\n",
    "\n",
    "        # determine the class label and color we'll use to draw\n",
    "        # the bounding box and text\n",
    "        label = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
    "        color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "\n",
    "        # include the probability in the label\n",
    "        label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "\n",
    "        # display the label and bounding box rectangle on the output\n",
    "        # frame\n",
    "        cv2.putText(frame, label, (startX, startY - 10),\n",
    "            font, 0.45, color, 2)\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "\n",
    "    # show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # esc key\n",
    "    if key == 27:\n",
    "        break\n",
    "`\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
